name: Scheduled Code Analysis

on:
  schedule:
    # –ö–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ 8:00 UTC (11:00 –ú–°–ö)
    - cron: '0 8 * * *'
  workflow_dispatch: # –†—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    inputs:
      directory:
        description: '–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞'
        required: true
        default: 'data/student_codes'
      output_name:
        description: '–ò–º—è –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤'
        required: true
        default: 'daily_analysis'

jobs:
  analyze:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # –ü–æ–ª–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run code analysis
        run: |
          mkdir -p data/reports
          python scripts/run_analysis.py "${{ github.event.inputs.directory || 'data/student_codes' }}" --output "data/reports/${{ github.event.inputs.output_name || 'daily_analysis' }}"

      - name: Generate trend analysis
        run: |
          python -c "
          # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–π
          import json
          import pandas as pd
          from datetime import datetime
          
          try:
              # –ß–∏—Ç–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –æ—Ç—á–µ—Ç—ã
              with open('data/reports/daily_analysis.json', 'r') as f:
                  current = json.load(f)
              
              # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
              history_file = 'data/reports/analysis_history.json'
              try:
                  with open(history_file, 'r') as f:
                      history = json.load(f)
              except:
                  history = {'entries': []}
              
              history['entries'].append({
                  'date': datetime.now().isoformat(),
                  'average_score': current['average_score'],
                  'total_files': current['total_files']
              })
              
              # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –∑–∞–ø–∏—Å–µ–π
              history['entries'] = history['entries'][-30:]
              
              with open(history_file, 'w') as f:
                  json.dump(history, f, indent=2)
              
              print('‚úÖ –ò—Å—Ç–æ—Ä–∏—è –∞–Ω–∞–ª–∏–∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞')
              
              # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ —Ç–µ–Ω–¥–µ–Ω—Ü–∏—è—Ö
              if len(history['entries']) > 1:
                  df = pd.DataFrame(history['entries'])
                  df['date'] = pd.to_datetime(df['date'])
                  
                  trend = 'üìà –£–ª—É—á—à–µ–Ω–∏–µ' if df['average_score'].iloc[-1] > df['average_score'].iloc[-2] else 'üìâ –£—Ö—É–¥—à–µ–Ω–∏–µ'
                  print(f'\nüìä –¢—Ä–µ–Ω–¥ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞: {trend}')
                  print(f'   –¢–µ–∫—É—â–∞—è –æ—Ü–µ–Ω–∫–∞: {df[\"average_score\"].iloc[-1]:.2f}')
                  print(f'   –ü—Ä–µ–¥—ã–¥—É—â–∞—è –æ—Ü–µ–Ω–∫–∞: {df[\"average_score\"].iloc[-2]:.2f}')
                  
          except Exception as e:
              print(f'‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ç—Ä–µ–Ω–¥–æ–≤: {e}')
          "

      - name: Create summary markdown
        run: |
          echo "# üìä –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –æ—Ç—á–µ—Ç –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞" > data/reports/DAILY_SUMMARY.md
          echo "–î–∞—Ç–∞: $(date '+%Y-%m-%d %H:%M:%S')" >> data/reports/DAILY_SUMMARY.md
          echo "" >> data/reports/DAILY_SUMMARY.md
          python -c "
          try:
              import json
              with open('data/reports/daily_analysis.json', 'r') as f:
                  data = json.load(f)
              
              print(f'## –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', file=open('data/reports/DAILY_SUMMARY.md', 'a'))
              print(f'- –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {data[\"total_files\"]}', file=open('data/reports/DAILY_SUMMARY.md', 'a'))
              print(f'- –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {data[\"average_score\"]:.2f}/100', file=open('data/reports/DAILY_SUMMARY.md', 'a'))
              
              # –¢–æ–ø-3 —Ñ–∞–π–ª–∞
              files = sorted(data['files'], key=lambda x: x['score'], reverse=True)
              print(f'\n## üèÜ –¢–æ–ø-3 —Ñ–∞–π–ª–∞', file=open('data/reports/DAILY_SUMMARY.md', 'a'))
              for i, f in enumerate(files[:3], 1):
                  print(f'{i}. **{f[\"filename\"]}** - {f[\"score\"]:.2f}/100', file=open('data/reports/DAILY_SUMMARY.md', 'a'))
              
          except Exception as e:
              print(f'–û—à–∏–±–∫–∞: {e}', file=open('data/reports/DAILY_SUMMARY.md', 'a'))
          "

      - name: Upload analysis artifacts
        uses: actions/upload-artifact@v4
        with:
          name: daily-code-analysis-${{ github.run_number }}
          path: |
            data/reports/
          retention-days: 90

      - name: Deploy to GitHub Pages (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        if: github.ref == 'refs/heads/main'
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./data/reports
          publish_branch: gh-pages
          keep_files: true

      - name: Send notification on low score
        if: failure()
        run: |
          python -c "
          import json
          try:
              with open('data/reports/daily_analysis.json', 'r') as f:
                  data = json.load(f)
              
              if data['average_score'] < 60:
                  print('üö® –í–ù–ò–ú–ê–ù–ò–ï: –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞ –Ω–∏–∂–µ 60!')
                  print('–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞.')
                  exit(1)
          except:
              pass
          "